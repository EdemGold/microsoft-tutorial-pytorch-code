{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t1.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysF20LQrFIzh"
      },
      "source": [
        "# Loading Data with PyTorch datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWm41JpQFQJg"
      },
      "source": [
        "#importing packages\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMr1UUB5ISVQ"
      },
      "source": [
        "#loading training data\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtd00oSiISaG"
      },
      "source": [
        "#loading test data\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqWU6pTvISeW"
      },
      "source": [
        "#iterating and visualizing datasets\n",
        "labels_map = {\n",
        "    0:\"T-Shirt\",\n",
        "    1:\"Trouser\",\n",
        "    2:\"Pullover\",\n",
        "    3:\"Dress\",\n",
        "    4:\"Coat\",\n",
        "    5:\"Sandal\",\n",
        "    6:\"Shirt\",\n",
        "    7:\"Sneaker\",\n",
        "    8:\"Bag\",\n",
        "    9:\"Ankle Boot\",\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8,8))\n",
        "cols, rows = 3,3\n",
        "for i in range(1, cols*rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCWqJnqtIShI"
      },
      "source": [
        "#buildimg a custom image dataset\n",
        "import os\n",
        "import pandas\n",
        "import torchvision.io\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = tvio.read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    sample = {\"image\":image, \"label\":label }\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGgu2DKQnzX9"
      },
      "source": [
        "The __init__ function is run when instantiating the dataset obect, we initialize the directory contaiing the images, annotations file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPmiBj2vISmf"
      },
      "source": [
        "def __init__(self, annotations_ffile, img_dir, transform=None, target_transform=None):\n",
        "  self.img_labels = pd.read_csv(annotations_file)\n",
        "  self.img_dir = img_dir\n",
        "  self.transform = transform\n",
        "  self.target_transform = target_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPO5CVjnqEnb"
      },
      "source": [
        "The __len__ function returns the number of samples in a dateste "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCz7-VNhISr7"
      },
      "source": [
        "def __len__(self):\n",
        "    return len(self.img_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlQNg-rWqyJH"
      },
      "source": [
        "The __getitem__ function loads and returns a sample from the dataset from the given index at __idx__, it locates the images location on disk and turns it into a tensor using __read image__ receives the image's label from the __self.img_labels__ calls the transform function (if applicable) and returns the image in tensor form in a coresponding python dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioQv1gpQs7iu"
      },
      "source": [
        "def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "    sample = {\"image\": image, \"label\": label}\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf3XJGyVsQfm"
      },
      "source": [
        "# Preparing your data for data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYpPm6mgsVBS"
      },
      "source": [
        "The __Dataset__  retrieves our datsets features and labels one instance at a time. When Trainig models we usually want to pass samples in __minibatches__, reshuffle the data at every __epoch__ to reduce model overfitting and make use of python's __multiprocessing__ top speed up data retrieval. __DataLoader__ is an iterbale that implements this complexity for us in a simple API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0PxY8NisPqy"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_DataLoader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "\n",
        "test_DataLoader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2i_SlfOwzq7"
      },
      "source": [
        "# Iterating Through Data Loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-TgSNo6w4bg"
      },
      "source": [
        "Each iteration below returns a batch of __train features__ and __train labels__. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBYywB5bISu4"
      },
      "source": [
        "#display image and label\n",
        "train_features, train_labels = next(iter(train_DataLoader))\n",
        "print(f\"Labels Batche size: {train_features.size()}\")\n",
        "print(f\"Labels Batch Size:{train_labels.size()}\")\n",
        "\n",
        "img = train_features[0].squeeze()\n",
        "\n",
        "label = train_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label:{label}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixq-f6sqISxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejY4UkKTIS1a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIvdTjumIS5l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF9mGuYqIS9t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}